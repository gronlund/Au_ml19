{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand in 1 - 2019 Machine Learning Class\n",
    "For the first hand in you will implement Logistic Regression and Softmax Regression for classification.\n",
    "The descriptions below describe what you are meant to do and hand in. \n",
    "\n",
    "**Start Early, Use The Study Cafe and the Discussion Board, Check Your Shapes, try and deal with numerial issues**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "### Implementing Logistic Regression\n",
    "In this exercise you must implement logistic regression and test it on the text classification.\n",
    "We have provided starter code in the file **logistic_regression.py**. \n",
    "Here you should complete the following methods to implement a Logistic Regression Classifier. \n",
    "\n",
    "* logistic \n",
    "* predict \n",
    "* score\n",
    "* cost_grad\n",
    "* fit\n",
    "\n",
    "where *predict, score, cost_grad, fit* are class methods of the classifier you must implement.\n",
    "The interface for each function is described in the file. \n",
    "\n",
    "All needed equations can be found in the slides.\n",
    "\n",
    "You can test your implementation by running *python logistic_regression.py*. \n",
    "This is a small non-exhaustive test. You should consider writing your own test cases.  \n",
    "\n",
    "Cost and gradient computations sometimes suffers from numerical issues if we are not careful. Exponentation of large numbers and log of small numbers can lead to numerical issues. It is possible to implement the algorithm to be more numerically stable if you do not compute numbers you do not need. The algorithm should work well enough even if you are not so carefull and it is not a requirement for passing the hand in to make the ultimate nummerically stable algorithm.\n",
    "\n",
    "### Applying Logistic Regression \n",
    "**Run python logistic_test.py** and see your in sample and test accuracy on the text classification on industri codes (real data)\n",
    "\n",
    "The code automatically saves the generated plot  to include in your report. With a correct implementation and setting of learning rate, batch_size, epochs **you should get above 95 percent test accuracy.**\n",
    "\n",
    "\n",
    "\n",
    "### Report\n",
    "Add a section called \"PART I: Logistic Regression\" with subsections \"Code\" and \"Theory\" to your report. In the code subsection you should have the following subsubsections\n",
    "\n",
    "* Summary and Results: \n",
    " Include the plot generated by logistic_test and include the in sample and test accuracy you achieve.\n",
    " Add at most two lines explaining the plot(s) and comment anything you believe sticks out.\n",
    " Explain if anything does not work.\n",
    "* Actual Code: Include in your handin code snippets **cost_grad** and **fit** (using for instance verbatim enviroment in latex)\n",
    "\n",
    "Furthermore you must answer the following three theoretical questions\n",
    "\n",
    "### Theoretical Questions\n",
    "\n",
    "1. What is the running time of your mini batch gradient descentt algorithm?\n",
    "  \n",
    "  The parameters:\n",
    "  * **n**: number of training samples\n",
    "  * **d**: dimensionality of training samples\n",
    "  * **epochs**: number of epochs run\n",
    "  * **mini_batch_size**: batch_size for mini_batch_gradient_descent\n",
    "  \n",
    "  Write both the time to compute the cost and the gradient for log_cost\n",
    "  You can assume that multiplying an $a \\times b$ matrix with a $b \\times c$ matrix takes $O(abc)$ time.\n",
    "\n",
    "\n",
    "2. Sanity Check:\n",
    "\n",
    "Assume you are using Logistic Regression for classyfing images of cats and dogs.\n",
    "What happens if we randomly permute the pixels in each image (with the same permutation) before we train the classifier? Will we get a classifier that is better, worse, or the same than if we used the raw data? Give a short explanation (at most three sentences). \n",
    "  HINT: The location of pixels relative to each other seem to hold some kind of information. Does a random permutation of all pixels position affect this locality? Does the model we use exploit pixel locality? For inspiration see the visualization of the softmax model applied to digits.\n",
    "\n",
    "3. Linear Separable Data:\n",
    "\n",
    "If the data is linearly separable, what happens\n",
    "to weights when we implement logistic regression with gradient\n",
    "descent? That is, how do the weights that minimize the negative log likelihood look like?\n",
    "You may assume that we have full precision (that is, ignore floating point errors) and we can run gradient descent as long as we want (i. e. what happens with the weights in the limit). \n",
    "\n",
    "Do they converge to some fixed number (fluctuate around it) or do they\n",
    "keep increasing in magnitude (absolute value)?\n",
    "\n",
    "Give a short explanation for your answer. You may include math if it helps (at most 5 lines).\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Regression\n",
    "\n",
    "\n",
    "### Implementing Softmax\n",
    "In \"*softmax.py*\" you must complete the implementation of \n",
    "\n",
    "* logistic\n",
    "* predict\n",
    "* score\n",
    "* cost_grad\n",
    "* fit\n",
    "\n",
    "The interface for each function is described in the file. All needed equations can be found in the slides and in the softmax notebook.\n",
    "Note that we have added a helper function **def one_in_k_encoding(vec, k)** that encodes a vector og length $n$ of integer labels with class labels in $0,\\dots, k-1$ to a $n \\times k$ matrix of one-in-k encoded labels.\n",
    "\n",
    "\n",
    "You can test your implementation by running \"*python softmax.py*\". \n",
    "This is a small non-exhaustive test. You should consider writing your own test cases.\n",
    "\n",
    "As for Logistic Regression, softmax sometimes suffers from numerical issues if we are not careful. Exponentation of large numbers and log of small numbers can lead to numerical issues. It is possible to implement the algorithm to be quite numerically stable if you use the trick provided in the note and ensure you do not take log to numbers you do not need to!\n",
    "\n",
    "### Applying Softmax\n",
    "- Run **python softmax_test.py -wine** to test your implementation on the wine data set.\n",
    "The built in python implementation we tested in week one got above 90 percent test accuracy, so your implemenation should so as well.\n",
    "\n",
    "- Run **python softmax_test.py -show_digits** show a small subset of the data set of MNIST digits, a data set for Optical Character Recognition \n",
    "- Run **python softmax_test.py -digits** to run you classifier on MNIST digits - the generated plot is automatically saved\n",
    "- Run **python softmax_test.py -visualize** to visualize the a classifier trained on MNIST digits - the generated plot is automatically saved\n",
    "\n",
    "You can tune the epochs, mini_batch_size, and initial learning rate from the command line i.e.\n",
    "\n",
    "**python softmax_test.py -show_digits -epochs 100 -lr 0.42 -bs 666**\n",
    "\n",
    "but the provided values should work well enough.\n",
    "\n",
    "### Report\n",
    "Add a section \"Part II: Softmax\" with subsections \"code\" and \"theory\" to your report. \n",
    "In the \"code\" subsection **you should do the same 2 points as you did for logistic regression**.\n",
    "\n",
    "Include the plots generated by softmax_test and remember to include the in sample and test accuracy achieved.\n",
    "\n",
    "There is a single theory question specified in the next section. \n",
    "\n",
    "\n",
    "### Theoretical Question(s):\n",
    "Assume that you use your softmax implementation on a problem with $K$ classes with n,d, epochs, batch_size defined as for logistic_regression.\n",
    "* What is the running time of your softmax implementation i.e how long does your implementation of cost_grad take to compute the cost and the gradient.\n",
    "\n",
    "\n",
    "# Uploading to Black Board\n",
    "Make a zip archive of the two code files **logistic.py and softmax.py**\n",
    "\n",
    "Upload one pdf with the report to blackboard together with the zip file.\n",
    "\n",
    "**Ensure you do upload the pdf separately!**\n",
    "\n",
    "**Remeber to put your names and student ids inside the pdf report!**\n",
    "\n",
    "**The PDF should be at the most 5 pages!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
